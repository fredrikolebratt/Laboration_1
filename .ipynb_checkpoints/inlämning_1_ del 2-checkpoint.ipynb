{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboration 2 - inl√§mning del 2 Analys av tweets fr√•n bokm√§ssan\n",
    "\n",
    "## Attribution David Johnsson, Uppsala University"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starta med att ladda in f√∂ljande moduler och s√§tt upp visualiseringsmilj√∂n f√∂r matplotlib\n",
    "\n",
    "1. `pandas` \n",
    "2. `textmining` \n",
    "Funktioner f√∂r statistisk textmining, fokuserad p√• bag-of-words model (som ni inte beh√∂ver s√§tta er in f√∂r denna kurs.f F√∂r den nyfikne eller vetgirige finns enkla f√∂rklaringar exempelvis [h√§r](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) eller [h√§r](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/), en enkel tutorial finns ocks√• [h√§r](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)) \n",
    "3. `wordcloud` - En visualiseringsmodul f√∂r att skapa ordmoln, vilket vi g√∂r i denna laboration.\n",
    "4. `matplotlib` \n",
    "5. `sklearn` -  Scikit-learn,ett pythonbibliotek f√∂r maskininl√§rningsalgoritmer, den kommer vi anv√§nda mycket i b√•de laboration 3 och 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K√∂r denna cell f√∂r att ladda in biblioteken och s√§tta upp v√•r milj√∂\n",
    "import pandas as pd\n",
    "import nltk as tm\n",
    "from nltk.corpus import stopwords\n",
    "import wordcloud\n",
    "import matplotlib\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# S√§tt upp visualiseringen\n",
    "%matplotlib inline\n",
    "matplotlib.pyplot.rcParams['figure.figsize'] = [10, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWords = set(stopwords.words('swedish'))\n",
    "stopWords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Analys av Twitterdata fr√•n bokm√§ssan\n",
    "\n",
    "Ni har blivit inhyrda som konsulter f√∂r en bokpublicist som vill att du ska ta reda p√• vilka teman och b√∂cker som har f√•tt mest uppm√§rksamhet p√• bokm√§ssan i G√∂teborg 2016. \n",
    "\n",
    "Er uppgift √§r att via Twitterdata unders√∂ka vilka √§mnen som f√•tt speciellt mycket uppm√§rksamhet f√∂r och under bokm√§ssan och presentera ett f√∂rslag till f√∂retaget du arbetar med vad som √§r l√§mpliga debatt√§mnen. \n",
    "\n",
    "Fokus h√§r √§r allts√• p√• att f√∂rst√• data, vilket √§r en viktigt del av pre-processering inf√∂r mer avacerad dataanalys. \n",
    "\n",
    "**F1.** Vad f√∂r data √§r distinkt f√∂r twitter och vilken typ av pre-processing tror ni kommer beh√∂vas p√• den typen av data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "## Data processing\n",
    "\n",
    "Som alltid beh√∂ver v√•rt data st√§das, i detta fall √§r fokus att sortera bort data som antingen inte g√•r att analysera eller inte √§r intressant fr√•n den r√•textdata vi f√•tt fr√•n Twitter. Den data som givits samlades in fr√•n Twitter fr√•n maj till september 2016.\n",
    "\n",
    "Er datafil finns i mappen data i laborationsrepositoriet och heter `twitter_book_fair_data.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Ladda data\n",
    "\n",
    "En `.tsv` fil betyder att det √§r en tab-separerad fil med tabelldata (j√§mf√∂rt med ; separerad som vi anv√§nt tidigare)\n",
    "\n",
    "**F2** Starta arbetet med att l√§sa in filen med read_csv() med f√∂ljande parametrar:  encoding=\"utf-8\", sep=\"\\t\" och spara i en dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F3** Inspektera den dataframe som skapats med l√§mpliga funktioner. Ta reda p√• f√∂ljande:\n",
    "\n",
    "Hur ser den ut?\n",
    "Antal kolumner och rader?\n",
    "Datatyper?\n",
    "\n",
    "Gl√∂m inte bort att n√§r du utf√∂r operationer p√• en datafram s√• sparas ingenting om du inte skapar en variabel som du lagrar dina √§ndringar i! (alternativt skriver √∂ver den dataframe du har genom att s√§tta parametern inplace = True (default √§r False)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F4** Finns det nullv√§rden i v√•rt dataset? Varf√∂r/varf√∂r inte?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F5.** Hur m√•nga tweets i v√•rt dataset √§r n√§mnanden av andra anv√§ndare (allts√• n√§r `@twittername` finns med i tweeten) \n",
    "\n",
    "*Hint: Det kan vara till hj√§lp att anv√§nda funktionen `info()`*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F6.** En kolumn √§r speciellt intressant f√∂r v√•r **textanalys**, extrahera den fr√•n den dataframe vi lagrat all data i och skapa en variabel d√§r du placerar denna data, d√∂p variablen till `tweets_corpus`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Emojis\n",
    "\n",
    "P√• Twitter √§r det v√§ldigt vanligt med emojis üëç ‚ú® üê´ üéâ üöÄ ü§ò.\n",
    "\n",
    "Dessa kan inneh√•lla mycket information som kan vara relevant f√∂r v√•r analys. Dock √§r det ofta sv√•rt att analysera emojis med hj√§lp av vanliga verktug f√∂r NLP(Natural Language Processig). \n",
    "\n",
    "Vi beh√∂ver d√§rf√∂r ta bort dessa ur v√•rt utvalda dataset som skapades i uppgiften ovan.\n",
    "\n",
    "F√∂ljande kod utf√∂r detta, ni beh√∂ver inte bry er om lambda just nu, men vi kommer g√• igenom det lite senare i kursen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encode2ascii = lambda x: x.encode('ascii', errors='ignore').decode('utf-8')\n",
    "clean_tweets = tweets_corpus.apply(encode2ascii)\n",
    "clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F7.** Hur p√•verkas kvaliteten p√• v√•r analys potentiellt av att ta bort alla emojis? F√∂rklara svaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Ta bort URLs\n",
    "Det √§r ocks√• vanligt att man p√• Twitter l√§nkar till olika webbplatser med hj√§lp av URL:er, n√§r man g√∂r textanalys p√• twitterdata √§r det vanligt att delar av dessa URL:er dyker upp som \"mest frekventa ord\" vilket p√•verkar v√•r analys negativs. Dessa beh√∂ver d√§rf√∂r ocks√• tas bort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = clean_tweets.str.replace(r'http\\S+', '')\n",
    "clean_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F8.** Hur kan borttagandet av URL:er pv√•erkar analysen och dess kvalitet, f√∂rklara svaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Funktion f√∂r att hitta mest frekventa ord \n",
    "\n",
    "Ett s√§tt att f√∂rst√• hur olika metoder f√∂r pre-processing p√•verkar ett dataset kan man r√§kna de mest f√∂rekommande orden efter varje operation som utf√∂rs. Eftersom vi kommer vilja utf√∂ra denna r√§kning m√•nga g√•nger under arbetet √§r de l√§mpligt att skapa en funktion f√∂r det som vi kan anropa flera g√•nger.\n",
    "\n",
    "#### Vad √§r en Term Document Matrix (TDM)?\n",
    "\n",
    "En TDM √§r en tabell d√§r antalet unika ord r√§knas f√∂r varje dokument. F√∂r att g√∂ra detta p√• v√•rt Twitterdata √§r det l√§mpligt att skapa en TDM d√§r varje tweet √§r en egen vektor d√§r varje element best√•r av de ord som finns i den tweeten. En tweet med tre unika ord blir allts√• en vektor med tre element. \n",
    "\n",
    "Nedanst√•ende kod skapar denna TDM i form av en funktion med namn `create_term_document_matrix()`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F9** Koden nedan √§r inte kommenterad, l√§gg in kommentarer som f√∂rklarar vad som sker i koden. (No hittar dokumentationen f√∂r CountVectorizer() [h√§r](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) och en kort beskrivning med exempel [h√§r](https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_term_document_matrix(corpus, min_df=1):\n",
    "    cvec = CountVectorizer(min_df=min_df, stop_words=stopWords)\n",
    "    tfmatrix = cvec.fit_transform(corpus)\n",
    "    return pd.DataFrame(data=tfmatrix.toarray(), columns=cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F10** Testa v√•r nya funktion genom att skapa en TDM endast f√∂r de tre f√∂rsta raderna i `clean_tweets` som kan sorteras ut med `.head(3)` funktionen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kod h√§r..\n",
    "create_term_document_matrix( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F11.** Hur m√•nga kolumner skapades i TDM:n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F√∂r att hitta de mest frekvent f√∂rekommander orden i v√•r TDM beh√∂ver vi r√§kna ord. Det √§r ocks√• l√§mpligt med en visualisering √∂ver dessa vanligast f√∂rekommande ord. √Ñven detta kommer vi beh√∂va g√∂ra flera g√•nger och d√§rf√∂r √§r det √•terigen l√§mpligt att definiera en funktion `plot_top_words()` som b√•de r√§knar och plottar orden i ett stapeldiagram. \n",
    "\n",
    "**F12** I nedanst√•ende cell √§r funktionen definierad, men koden √§r √•terigen inte kommenterad, skapa kommentarer (eller skriv i en markdowncell) som f√∂rklarar vad funktionen g√∂r. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_top_words(tweets, num_word_instances, top_words):\n",
    "    tdm_df = create_term_document_matrix(tweets, min_df=2)\n",
    "    word_frequencies = tdm_df[[x for x in tdm_df.columns if len(x) > 1]].sum()\n",
    "    sorted_words = word_frequencies.sort_values(ascending=False)\n",
    "    top_sorted_words = sorted_words[:num_word_instances]\n",
    "    top_sorted_words[:top_words].plot.bar()\n",
    "    return top_sorted_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan vi anv√§nda `plot_top_words()` funktionen f√∂r att r√§kna ut de mest f√∂rekommande orden i hela v√•rt corpus, viktigt att ha t√•lamod dock f√∂r det kan ta ett tag. Nedanst√•ende kod utf√∂r ber√§kningen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words = plot_top_words(clean_tweets, 50, 30)\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F13** Hur m√•nga g√•nger m√•ste ett ord finnas i corpuset f√∂r att finnas med i `top_words` s√• som den √§r skriven ovan?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F14.** Hur m√•nga ord plottas i stapeldiagrammet? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Sm√• bokst√§ver\n",
    "\n",
    "N√§sta steg i pre-processingen av v√•rt dataset (v√•rt corpus) √§r att g√∂ra om alla bokst√§ver till sm√•. \n",
    "\n",
    "**F15** \n",
    "\n",
    "a.Utf√∂r √§ndringen att alla stora bokst√§ver blir sm√• bokst√§ver i `clean_tweets` och spara i en ny variabel kallad `tweets_lowered`\n",
    "\n",
    "b.Varf√∂r vill man g√∂ra det f√∂r v√•r analys?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F16** R√§kna ut en ny variabel med de mest f√∂rekommander (frekventa) orden, d√∂p den till `top_words_lowered`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Skriv klart denna kodcell f√∂r F1.16\n",
    "\n",
    "top_words_lowered = ...\n",
    "top_words_lowered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F17.** Har n√•got f√∂r√§ndrats, vad? F√∂rklara svaret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "F√∂r att underl√§tta att j√§mf√∂ra vad v√•ra anstr√§ngningar f√•r f√∂r resultat kan det vara bra att enkelt kunna j√§mf√∂ra olika listor med top_words.\n",
    "\n",
    "**F18** Skapa en ny dataframe som har tv√• kolumner, en med de 20 mest frekventa orden fr√•n`top_words` och en med de 20 mest frekventa orden fr√•n `top_word_lowered`. D√∂p kolumnerna till `Top tweeted clean`och  `Top tweeted lowered`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\n",
    "    'Top tweeted clean': top_words[0:20].index,\n",
    "    'Top tweeted lowered': top_words_lowered[0:20].index\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "Ett annnat s√§tt att g√∂ra ungef√§r samma sak, fast lite mer automatiskt √§r nedanst√•ende kod som ocks√• j√§mf√∂r de f√∂rsta 20 orden. G√∂r om den s√• att den ist√§llet f√∂r att j√§mf√∂ra de 20 mest frekventa orden, j√§mf√∂r de ord som √§r minst f√∂rekommande i de tv√• listorna `top_words`och `top_words_lowered`.\n",
    "\n",
    "**F19** Vad returnerar nedanst√•ende kodrad om de tv√• listor som j√§mf√∂rs √§r identiska? Vad returneras om de inte √§r identiska?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(top_words[0:20].index) - set(top_words_lowered[0:20].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korta ord\n",
    "\n",
    "Korta ord har ofta inte n√•gon egentlig betydelse, allts√• beh√∂ver vi inte dessa ord. Typiska s√•dana ord kan vara ja, jo eller nej. Vi best√§mmer oss f√∂r att alla ord som √§r kortare √§n 3 bokst√§ver inte innehar n√•gon betydelse i v√•r analys och tar d√§rmed bort dem. \n",
    "\n",
    "**F20** Ta bort alla ord med f√§rre bokst√§ver √§n 3(HINT: [regular expressions](https://docs.python.org/3/howto/regex.html)), l√§gg den nya listan med ord (som inte inneh√•ller ord med f√§rre bokst√§ver √§n 3) i en variabel med namn `tweets_low_no_small`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_low_no_small = ...#din kod h√§r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Skapar ny topplista utan korta ord\n",
    "top_words_low_no_small = plot_top_words(tweets_low_no_small, 50, 30)\n",
    "top_words_low_no_small"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F21.** Efter att korta ord tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Betydelsel√∂sa ord\n",
    "\n",
    "Stop words √§r andra ord som inte √§r korta men som √§nd√• inte har betydelse, dessa kan vara lite besv√§rligare att identifiera och ta bort. En m√∂jlighet √§r att helt enkelt skapa en lista med s√•dana ord och sedan anv√§nda den listan f√∂r att filtrera ut orden ur ett corpus. Vi har ju redan tagit bort alla ord med f√§rre bokst√§ver √§n 3, s√• s√•dana beh√∂ver vi inte l√§gga in i listan. \n",
    "\n",
    "Nedan √§r ett exempel p√• en lista med stoppord som √§r betydelsel√∂sa. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stop_words = [\"och\", \"det\", \"att\", \"i\", \"en\", \"jag\", \"hon\", \n",
    "                \"som\", \"han\", \"paa\", \"den\", \"med\", \"var\", \"sig\", \n",
    "                \"foer\", \"saa\", \"till\", \"aer\", \"men\", \"ett\", \n",
    "                \"om\", \"hade\", \"de\", \"av\", \"icke\", \"mig\", \"du\", \n",
    "                \"henne\", \"daa\", \"sin\", \"nu\", \"har\", \"inte\", \n",
    "                \"hans\", \"honom\", \"skulle\", \"hennes\", \"daer\", \n",
    "                \"min\", \"man\", \"ej\", \"vid\", \"kunde\", \"naagot\", \n",
    "                \"fraan\", \"ut\", \"naer\", \"efter\", \"upp\", \"vi\", \n",
    "                \"dem\", \"vara\", \"vad\", \"oever\", \"aen\", \"dig\", \n",
    "                \"kan\", \"sina\", \"haer\", \"ha\", \"mot\", \"alla\", \n",
    "                \"under\", \"naagon\", \"eller\", \"allt\", \"mycket\", \n",
    "                \"sedan\", \"ju\", \"denna\", \"sjaelv\", \"detta\", \n",
    "                \"aat\", \"utan\", \"varit\", \"hur\", \"ingen\", \"mitt\", \n",
    "                \"ni\", \"bli\", \"blev\", \"oss\", \"din\", \"dessa\", \n",
    "                \"naagra\", \"deras\", \"blir\", \"mina\", \"samma\", \n",
    "                \"vilken\", \"er\", \"saadan\", \"vaar\", \"blivit\", \n",
    "                \"dess\", \"inom\", \"mellan\", \"saadant\", \"varfoer\", \n",
    "                \"varje\", \"vilka\", \"ditt\", \"vem\", \"vilket\", \n",
    "                \"sitta\", \"saadana\", \"vart\", \"dina\", \"vars\", \n",
    "                \"vaart\", \"vaara\", \"ert\", \"era\", \"vilka\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "N√§r vi skapat v√•r lista √§r det dags att skapa en funktion som tar bort dessa fr√•n ett dokument. Denna funktion √§r kodad i cellen nedan. (Igen strunta i lambda f√∂r tillf√§llet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords = lambda x: ' '.join(y for y in x.split() if y not in my_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funktionen ovan tar allts√• bort stoppord fr√•n ett dokument (allts√• en tweet), f√∂r att ta bort stoppord fr√•n hela v√•rt corpus kan funktionen `.apply()`anv√§ndas. \n",
    "\n",
    "**F22.** Skriv den kod som tar bort alla stoppord fr√•n `tweets_low_no_small` och skapar en ny variabel `tweets_low_no_small_stopwords` f√∂r corpuset utan stoppord."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_low_no_small_stopwords = ...#din kod h√§r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_words_low_no_small_stopwords = plot_top_words(tweets_low_no_small_stopwords, 50, 30)\n",
    "top_words_low_no_small_stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F23.** Efter att stopporden tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F24.** Vad √§r skillnaderna mellan de frekvent f√∂rekommande orden i j√§mf√∂relse med v√•ra tidigare listor? Skriv den kod som j√§mf√∂r dessa tre listor `top_words_lowered`, `top_words_low_no_small` and `top_words_low_no_small_stopwords`, titta p√• de f√∂rsta 20 orden i listorna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "### Visualisering och rekommendation\n",
    "\n",
    "Dags att visualisera v√•rt resultat och √∂vertyga v√•r klient om att vi hittat de b√§sta debatt√§mnena f√∂r dem! H√§r g√∂r vi det genom att skapa ett word cloud d√§r de mest frekventa orden syns b√§st. \n",
    "\n",
    "Nedanst√•ende kod skapar ett ordmoln f√∂r `top_words_low_no_small_stopwords`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "wordcloud = WordCloud(max_font_size=40)\n",
    "wordcloud.fit_words(top_words_no_small_stopwords.to_dict())\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F25** √Ñndra i tidigare kod hur m√•nga g√•nger ett ord minst m√•ste finnas f√∂r att det ska inkluderas i ordmolnet. Vad f√∂r√§ndras?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F26** N√§r du tittar p√• ordmolnet, √§r det fler ord som borde vara stoppord? Ange n√•gra stycken och f√∂rklara varf√∂r de b√∂r tas bort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F27.** Vilket tema rekommenderar ni att publicisten ska ha som debatt√§mne? F√∂rklara svaret. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lang": "en"
   },
   "source": [
    "**F28.** Ni har nu arbetat med textdata, hur √§r det annorlunda n√§r det g√§ller pre-processing j√§mf√∂rt med annan typ av data som √§r av mer numerisk eller kategorisk karakt√§r?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "*N√§r ni besvarat samtliga fr√•gor och all er kod fungerar i enlighet med instruktioner, gl√∂m d√• inte att l√§mna in en l√§nk till ert repositorie med den f√§rdiga l√∂sningen k√∂rd i era notebooks, senast det datum som √§r angivet. Infoga ocks√• en knapp till Colaboratory om ni anv√§nt er av denna milj√∂*. \n",
    "\n",
    "**Gl√∂m inte heller att versionshantera i GitHub s√• att jag kan f√∂lja ert arbete!** \n",
    "\n",
    "Lycka till!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "sv",
   "targetLang": "en",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
