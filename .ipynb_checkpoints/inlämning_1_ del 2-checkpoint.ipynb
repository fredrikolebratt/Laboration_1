{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    },
    "nbTranslate": {
      "displayLangs": [],
      "hotkey": "alt-t",
      "langInMainMenu": true,
      "sourceLang": "sv",
      "targetLang": "en",
      "useGoogleTranslate": true
    },
    "colab": {
      "name": "inl√§mning_1_ del 2-checkpoint.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKsUjOOYa0nm"
      },
      "source": [
        "# Laboration 2 - inl√§mning del 2 Analys av tweets fr√•n bokm√§ssan\n",
        "\n",
        "## Attribution David Johnsson, Uppsala University"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEFdILD6a0np"
      },
      "source": [
        "Starta med att ladda in f√∂ljande moduler och s√§tt upp visualiseringsmilj√∂n f√∂r matplotlib\n",
        "\n",
        "1. `pandas` \n",
        "2. `textmining` \n",
        "Funktioner f√∂r statistisk textmining, fokuserad p√• bag-of-words model (som ni inte beh√∂ver s√§tta er in f√∂r denna kurs.f F√∂r den nyfikne eller vetgirige finns enkla f√∂rklaringar exempelvis [h√§r](https://www.analyticsvidhya.com/blog/2020/02/quick-introduction-bag-of-words-bow-tf-idf/) eller [h√§r](https://www.geeksforgeeks.org/bag-of-words-bow-model-in-nlp/), en enkel tutorial finns ocks√• [h√§r](https://machinelearningmastery.com/gentle-introduction-bag-words-model/)) \n",
        "3. `wordcloud` - En visualiseringsmodul f√∂r att skapa ordmoln, vilket vi g√∂r i denna laboration.\n",
        "4. `matplotlib` \n",
        "5. `sklearn` -  Scikit-learn,ett pythonbibliotek f√∂r maskininl√§rningsalgoritmer, den kommer vi anv√§nda mycket i b√•de laboration 3 och 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1GiMFZha0np"
      },
      "source": [
        "pip install nltk "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOpvdSfqa0nq"
      },
      "source": [
        "# K√∂r denna cell f√∂r att ladda in biblioteken och s√§tta upp v√•r milj√∂\n",
        "import pandas as pd\n",
        "import nltk as tm\n",
        "from nltk.corpus import stopwords\n",
        "import wordcloud\n",
        "import matplotlib\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "# S√§tt upp visualiseringen\n",
        "%matplotlib inline\n",
        "matplotlib.pyplot.rcParams['figure.figsize'] = [10, 6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-C2riC_a0nr"
      },
      "source": [
        "tm.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zg7ECRmma0nr"
      },
      "source": [
        "stopWords = set(stopwords.words('swedish'))\n",
        "stopWords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "KNPjnXqaa0nr"
      },
      "source": [
        "## Analys av Twitterdata fr√•n bokm√§ssan\n",
        "\n",
        "Ni har blivit inhyrda som konsulter f√∂r en bokpublicist som vill att du ska ta reda p√• vilka teman och b√∂cker som har f√•tt mest uppm√§rksamhet p√• bokm√§ssan i G√∂teborg 2016. \n",
        "\n",
        "Er uppgift √§r att via Twitterdata unders√∂ka vilka √§mnen som f√•tt speciellt mycket uppm√§rksamhet f√∂r och under bokm√§ssan och presentera ett f√∂rslag till f√∂retaget du arbetar med vad som √§r l√§mpliga debatt√§mnen. \n",
        "\n",
        "Fokus h√§r √§r allts√• p√• att f√∂rst√• data, vilket √§r en viktigt del av pre-processering inf√∂r mer avacerad dataanalys. \n",
        "\n",
        "**F1.** Vad f√∂r data √§r distinkt f√∂r twitter och vilken typ av pre-processing tror ni kommer beh√∂vas p√• den typen av data? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExW3Vh4Ud13R"
      },
      "source": [
        "Tweets, Retweets, likes, and Direct Messages √§r distinkt data f√∂r twitter och vi tror att data wrangling kommer att beh√∂vas f√∂r att g√∂ra datan mer anspassad f√∂r att analyseras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "gOULcxjoa0ns"
      },
      "source": [
        "## Data processing\n",
        "\n",
        "Som alltid beh√∂ver v√•rt data st√§das, i detta fall √§r fokus att sortera bort data som antingen inte g√•r att analysera eller inte √§r intressant fr√•n den r√•textdata vi f√•tt fr√•n Twitter. Den data som givits samlades in fr√•n Twitter fr√•n maj till september 2016.\n",
        "\n",
        "Er datafil finns i mappen data i laborationsrepositoriet och heter `twitter_book_fair_data.tsv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "_Ro_zvP3a0nt"
      },
      "source": [
        "### Ladda data\n",
        "\n",
        "En `.tsv` fil betyder att det √§r en tab-separerad fil med tabelldata (j√§mf√∂rt med ; separerad som vi anv√§nt tidigare)\n",
        "\n",
        "**F2** Starta arbetet med att l√§sa in filen med read_csv() med f√∂ljande parametrar:  encoding=\"utf-8\", sep=\"\\t\" och spara i en dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMB5wkldi7h1",
        "outputId": "121f412d-a2d2-4cd5-f693-4bd7b0285e27"
      },
      "source": [
        "import pandas as pd\n",
        "url = 'https://raw.githubusercontent.com/2IS239-Data-Analytics/laboration_1-laborationsgrupp-5/master/Data/twitter_book_fair_data.tsv?token=AVONS6CFLO7TGFGBT62J7T3BHYK7E'\n",
        "\n",
        "df = pd.read_csv(url, encoding = 'UTF-8', sep=\"\\t\")\n",
        "print(df)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                   text  ...          time\n",
            "0     rt @amiethekid: kvaellens avsnitt av raseriet ...  ...  1.474960e+09\n",
            "1     maranatafoersamlingens monter paa bokmaessan v...  ...  1.474958e+09\n",
            "2     idrotten blev en trygg zon under en jobbig ton...  ...  1.474958e+09\n",
            "3     tillbakablick paa #bokmaessan #goeteborg del 1...  ...  1.474957e+09\n",
            "4     rt @flamman_: aha, vilken tid aer demon? hm, d...  ...  1.474957e+09\n",
            "...                                                 ...  ...           ...\n",
            "9995  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
            "9996  rt @viskot: apropaa #bokmaessan och det haer m...  ...  1.471694e+09\n",
            "9997  rt @charlieafnord: hej @bokmassangbg. kommer n...  ...  1.471694e+09\n",
            "9998  rt @mxcartoons: nya tider kommenterar bokmaess...  ...  1.471694e+09\n",
            "9999  rt @dolf371: tystnad aer yttrandefrihet ‚Äì #bok...  ...  1.471694e+09\n",
            "\n",
            "[10000 rows x 13 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "LwcHaR7Na0nt"
      },
      "source": [
        "**F3** Inspektera den dataframe som skapats med l√§mpliga funktioner. Ta reda p√• f√∂ljande:\n",
        "\n",
        "Hur ser den ut?\n",
        "Antal kolumner och rader?\n",
        "Datatyper?\n",
        "\n",
        "Gl√∂m inte bort att n√§r du utf√∂r operationer p√• en datafram s√• sparas ingenting om du inte skapar en variabel som du lagrar dina √§ndringar i! (alternativt skriver √∂ver den dataframe du har genom att s√§tta parametern inplace = True (default √§r False)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj7dYdteCj58",
        "outputId": "840819e3-d3e9-4466-ad8a-6066d79f5353"
      },
      "source": [
        "\n",
        "df.info()\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   text               10000 non-null  object \n",
            " 1   to_user_id         428 non-null    object \n",
            " 2   from_user          9996 non-null   object \n",
            " 3   id                 10000 non-null  int64  \n",
            " 4   from_user_id       10000 non-null  int64  \n",
            " 5   iso_language_code  10000 non-null  object \n",
            " 6   source             10000 non-null  object \n",
            " 7   profile_image_url  9589 non-null   object \n",
            " 8   geo_type           115 non-null    object \n",
            " 9   geo_coordinates_0  9996 non-null   float64\n",
            " 10  geo_coordinates_1  9996 non-null   float64\n",
            " 11  created_at         9996 non-null   object \n",
            " 12  time               9996 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(8)\n",
            "memory usage: 1015.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF0k5S8Aa0nt"
      },
      "source": [
        "**F4** Finns det nullv√§rden i v√•rt dataset? Varf√∂r/varf√∂r inte?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eygG85CVh-Dc",
        "outputId": "fdeffb5e-6088-47ba-dc4d-70e94a13cae9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "null = df.isnull().sum()\n",
        "print(null)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text                    0\n",
            "to_user_id           9572\n",
            "from_user               4\n",
            "id                      0\n",
            "from_user_id            0\n",
            "iso_language_code       0\n",
            "source                  0\n",
            "profile_image_url     411\n",
            "geo_type             9885\n",
            "geo_coordinates_0       4\n",
            "geo_coordinates_1       4\n",
            "created_at              4\n",
            "time                    4\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XTwvuClwhzMx"
      },
      "source": [
        "Det finns nullv√§rden eftersom anv√§ndare inte alltid vill dela all information som man kan l√§gga in.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5g2MhHuGa0nu"
      },
      "source": [
        "**F5.** Hur m√•nga tweets i v√•rt dataset √§r n√§mnanden av andra anv√§ndare (allts√• n√§r `@twittername` finns med i tweeten) \n",
        "\n",
        "*Hint: Det kan vara till hj√§lp att anv√§nda funktionen `info()`*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HliPhV_JD45f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c468f1c0-2dce-4aef-a07a-7814721b27f4"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10000 entries, 0 to 9999\n",
            "Data columns (total 13 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   text               10000 non-null  object \n",
            " 1   to_user_id         428 non-null    object \n",
            " 2   from_user          9996 non-null   object \n",
            " 3   id                 10000 non-null  int64  \n",
            " 4   from_user_id       10000 non-null  int64  \n",
            " 5   iso_language_code  10000 non-null  object \n",
            " 6   source             10000 non-null  object \n",
            " 7   profile_image_url  9589 non-null   object \n",
            " 8   geo_type           115 non-null    object \n",
            " 9   geo_coordinates_0  9996 non-null   float64\n",
            " 10  geo_coordinates_1  9996 non-null   float64\n",
            " 11  created_at         9996 non-null   object \n",
            " 12  time               9996 non-null   float64\n",
            "dtypes: float64(3), int64(2), object(8)\n",
            "memory usage: 1015.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "dSCt2TcTa0nu"
      },
      "source": [
        "**F6.** En kolumn √§r speciellt intressant f√∂r v√•r **textanalys**, extrahera den fr√•n den dataframe vi lagrat all data i och skapa en variabel d√§r du placerar denna data, d√∂p variablen till `tweets_corpus`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "t3CjSN3wa0nu"
      },
      "source": [
        "### Emojis\n",
        "\n",
        "P√• Twitter √§r det v√§ldigt vanligt med emojis üëç ‚ú® üê´ üéâ üöÄ ü§ò.\n",
        "\n",
        "Dessa kan inneh√•lla mycket information som kan vara relevant f√∂r v√•r analys. Dock √§r det ofta sv√•rt att analysera emojis med hj√§lp av vanliga verktug f√∂r NLP(Natural Language Processig). \n",
        "\n",
        "Vi beh√∂ver d√§rf√∂r ta bort dessa ur v√•rt utvalda dataset som skapades i uppgiften ovan.\n",
        "\n",
        "F√∂ljande kod utf√∂r detta, ni beh√∂ver inte bry er om lambda just nu, men vi kommer g√• igenom det lite senare i kursen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "flwggZawa0nu"
      },
      "source": [
        "encode2ascii = lambda x: x.encode('ascii', errors='ignore').decode('utf-8')\n",
        "clean_tweets = tweets_corpus.apply(encode2ascii)\n",
        "clean_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "6OXwLlbra0nv"
      },
      "source": [
        "**F7.** Hur p√•verkas kvaliteten p√• v√•r analys potentiellt av att ta bort alla emojis? F√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "8oazelWva0nv"
      },
      "source": [
        "### Ta bort URLs\n",
        "Det √§r ocks√• vanligt att man p√• Twitter l√§nkar till olika webbplatser med hj√§lp av URL:er, n√§r man g√∂r textanalys p√• twitterdata √§r det vanligt att delar av dessa URL:er dyker upp som \"mest frekventa ord\" vilket p√•verkar v√•r analys negativs. Dessa beh√∂ver d√§rf√∂r ocks√• tas bort."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz322Vk9a0nv"
      },
      "source": [
        "clean_tweets = clean_tweets.str.replace(r'http\\S+', '')\n",
        "clean_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbw1IsZ4a0nv"
      },
      "source": [
        "**F8.** Hur kan borttagandet av URL:er pv√•erkar analysen och dess kvalitet, f√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "5CEmA7sKa0nw"
      },
      "source": [
        "### Funktion f√∂r att hitta mest frekventa ord \n",
        "\n",
        "Ett s√§tt att f√∂rst√• hur olika metoder f√∂r pre-processing p√•verkar ett dataset kan man r√§kna de mest f√∂rekommande orden efter varje operation som utf√∂rs. Eftersom vi kommer vilja utf√∂ra denna r√§kning m√•nga g√•nger under arbetet √§r de l√§mpligt att skapa en funktion f√∂r det som vi kan anropa flera g√•nger.\n",
        "\n",
        "#### Vad √§r en Term Document Matrix (TDM)?\n",
        "\n",
        "En TDM √§r en tabell d√§r antalet unika ord r√§knas f√∂r varje dokument. F√∂r att g√∂ra detta p√• v√•rt Twitterdata √§r det l√§mpligt att skapa en TDM d√§r varje tweet √§r en egen vektor d√§r varje element best√•r av de ord som finns i den tweeten. En tweet med tre unika ord blir allts√• en vektor med tre element. \n",
        "\n",
        "Nedanst√•ende kod skapar denna TDM i form av en funktion med namn `create_term_document_matrix()`:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEzwN6ICa0nw"
      },
      "source": [
        "**F9** Koden nedan √§r inte kommenterad, l√§gg in kommentarer som f√∂rklarar vad som sker i koden. (No hittar dokumentationen f√∂r CountVectorizer() [h√§r](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) och en kort beskrivning med exempel [h√§r](https://www.geeksforgeeks.org/using-countvectorizer-to-extracting-features-from-text/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTvoyCija0nw"
      },
      "source": [
        "def create_term_document_matrix(corpus, min_df=1):\n",
        "    cvec = CountVectorizer(min_df=min_df, stop_words=stopWords)\n",
        "    tfmatrix = cvec.fit_transform(corpus)\n",
        "    return pd.DataFrame(data=tfmatrix.toarray(), columns=cvec.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "91UNu7Kba0nw"
      },
      "source": [
        "**F10** Testa v√•r nya funktion genom att skapa en TDM endast f√∂r de tre f√∂rsta raderna i `clean_tweets` som kan sorteras ut med `.head(3)` funktionen. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ss6fsPMna0nw"
      },
      "source": [
        "#kod h√§r..\n",
        "create_term_document_matrix( )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9AAF400a0nx"
      },
      "source": [
        "**F11.** Hur m√•nga kolumner skapades i TDM:n?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fqPpep0ra0nx"
      },
      "source": [
        "F√∂r att hitta de mest frekvent f√∂rekommander orden i v√•r TDM beh√∂ver vi r√§kna ord. Det √§r ocks√• l√§mpligt med en visualisering √∂ver dessa vanligast f√∂rekommande ord. √Ñven detta kommer vi beh√∂va g√∂ra flera g√•nger och d√§rf√∂r √§r det √•terigen l√§mpligt att definiera en funktion `plot_top_words()` som b√•de r√§knar och plottar orden i ett stapeldiagram. \n",
        "\n",
        "**F12** I nedanst√•ende cell √§r funktionen definierad, men koden √§r √•terigen inte kommenterad, skapa kommentarer (eller skriv i en markdowncell) som f√∂rklarar vad funktionen g√∂r. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIqKozQoa0nx"
      },
      "source": [
        "def plot_top_words(tweets, num_word_instances, top_words):\n",
        "    tdm_df = create_term_document_matrix(tweets, min_df=2)\n",
        "    word_frequencies = tdm_df[[x for x in tdm_df.columns if len(x) > 1]].sum()\n",
        "    sorted_words = word_frequencies.sort_values(ascending=False)\n",
        "    top_sorted_words = sorted_words[:num_word_instances]\n",
        "    top_sorted_words[:top_words].plot.bar()\n",
        "    return top_sorted_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqEM4EjOa0nx"
      },
      "source": [
        "Nu kan vi anv√§nda `plot_top_words()` funktionen f√∂r att r√§kna ut de mest f√∂rekommande orden i hela v√•rt corpus, viktigt att ha t√•lamod dock f√∂r det kan ta ett tag. Nedanst√•ende kod utf√∂r ber√§kningen."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97N_g_C5a0nx"
      },
      "source": [
        "top_words = plot_top_words(clean_tweets, 50, 30)\n",
        "top_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GbsJrwxa0nx"
      },
      "source": [
        "**F13** Hur m√•nga g√•nger m√•ste ett ord finnas i corpuset f√∂r att finnas med i `top_words` s√• som den √§r skriven ovan?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pA4t7KKKa0nx"
      },
      "source": [
        "**F14.** Hur m√•nga ord plottas i stapeldiagrammet? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "QwTVFxdoa0nx"
      },
      "source": [
        "### Sm√• bokst√§ver\n",
        "\n",
        "N√§sta steg i pre-processingen av v√•rt dataset (v√•rt corpus) √§r att g√∂ra om alla bokst√§ver till sm√•. \n",
        "\n",
        "**F15** \n",
        "\n",
        "a.Utf√∂r √§ndringen att alla stora bokst√§ver blir sm√• bokst√§ver i `clean_tweets` och spara i en ny variabel kallad `tweets_lowered`\n",
        "\n",
        "b.Varf√∂r vill man g√∂ra det f√∂r v√•r analys?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LYK9K4aa0ny"
      },
      "source": [
        "**F16** R√§kna ut en ny variabel med de mest f√∂rekommander (frekventa) orden, d√∂p den till `top_words_lowered`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjqjyXUQa0ny",
        "outputId": "4606a229-b7ca-47e6-99cb-9dd14d069256"
      },
      "source": [
        "#Skriv klart denna kodcell f√∂r F1.16\n",
        "\n",
        "top_words_lowered = ...\n",
        "top_words_lowered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ellipsis"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vomYC_wwa0ny"
      },
      "source": [
        "**F17.** Har n√•got f√∂r√§ndrats, vad? F√∂rklara svaret."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "WmSnDxk-a0nz"
      },
      "source": [
        "F√∂r att underl√§tta att j√§mf√∂ra vad v√•ra anstr√§ngningar f√•r f√∂r resultat kan det vara bra att enkelt kunna j√§mf√∂ra olika listor med top_words.\n",
        "\n",
        "**F18** Skapa en ny dataframe som har tv√• kolumner, en med de 20 mest frekventa orden fr√•n`top_words` och en med de 20 mest frekventa orden fr√•n `top_word_lowered`. D√∂p kolumnerna till `Top tweeted clean`och  `Top tweeted lowered`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AqW_x2Ua0nz"
      },
      "source": [
        "pd.DataFrame({\n",
        "    'Top tweeted clean': top_words[0:20].index,\n",
        "    'Top tweeted lowered': top_words_lowered[0:20].index\n",
        "})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "1GLnjMeJa0nz"
      },
      "source": [
        "Ett annnat s√§tt att g√∂ra ungef√§r samma sak, fast lite mer automatiskt √§r nedanst√•ende kod som ocks√• j√§mf√∂r de f√∂rsta 20 orden. G√∂r om den s√• att den ist√§llet f√∂r att j√§mf√∂ra de 20 mest frekventa orden, j√§mf√∂r de ord som √§r minst f√∂rekommande i de tv√• listorna `top_words`och `top_words_lowered`.\n",
        "\n",
        "**F19** Vad returnerar nedanst√•ende kodrad om de tv√• listor som j√§mf√∂rs √§r identiska? Vad returneras om de inte √§r identiska?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RhRfMbQa0nz"
      },
      "source": [
        "set(top_words[0:20].index) - set(top_words_lowered[0:20].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kaswky3Sa0nz"
      },
      "source": [
        "### Korta ord\n",
        "\n",
        "Korta ord har ofta inte n√•gon egentlig betydelse, allts√• beh√∂ver vi inte dessa ord. Typiska s√•dana ord kan vara ja, jo eller nej. Vi best√§mmer oss f√∂r att alla ord som √§r kortare √§n 3 bokst√§ver inte innehar n√•gon betydelse i v√•r analys och tar d√§rmed bort dem. \n",
        "\n",
        "**F20** Ta bort alla ord med f√§rre bokst√§ver √§n 3(HINT: [regular expressions](https://docs.python.org/3/howto/regex.html)), l√§gg den nya listan med ord (som inte inneh√•ller ord med f√§rre bokst√§ver √§n 3) i en variabel med namn `tweets_low_no_small`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogkv7hGra0nz"
      },
      "source": [
        "tweets_low_no_small = ...#din kod h√§r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si8LAW4Ia0nz"
      },
      "source": [
        "#Skapar ny topplista utan korta ord\n",
        "top_words_low_no_small = plot_top_words(tweets_low_no_small, 50, 30)\n",
        "top_words_low_no_small"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_mcMCUfa0n0"
      },
      "source": [
        "**F21.** Efter att korta ord tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "SfnIalH3a0n0"
      },
      "source": [
        "### Betydelsel√∂sa ord\n",
        "\n",
        "Stop words √§r andra ord som inte √§r korta men som √§nd√• inte har betydelse, dessa kan vara lite besv√§rligare att identifiera och ta bort. En m√∂jlighet √§r att helt enkelt skapa en lista med s√•dana ord och sedan anv√§nda den listan f√∂r att filtrera ut orden ur ett corpus. Vi har ju redan tagit bort alla ord med f√§rre bokst√§ver √§n 3, s√• s√•dana beh√∂ver vi inte l√§gga in i listan. \n",
        "\n",
        "Nedan √§r ett exempel p√• en lista med stoppord som √§r betydelsel√∂sa. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHa-BVhLa0n0"
      },
      "source": [
        "my_stop_words = [\"och\", \"det\", \"att\", \"i\", \"en\", \"jag\", \"hon\", \n",
        "                \"som\", \"han\", \"paa\", \"den\", \"med\", \"var\", \"sig\", \n",
        "                \"foer\", \"saa\", \"till\", \"aer\", \"men\", \"ett\", \n",
        "                \"om\", \"hade\", \"de\", \"av\", \"icke\", \"mig\", \"du\", \n",
        "                \"henne\", \"daa\", \"sin\", \"nu\", \"har\", \"inte\", \n",
        "                \"hans\", \"honom\", \"skulle\", \"hennes\", \"daer\", \n",
        "                \"min\", \"man\", \"ej\", \"vid\", \"kunde\", \"naagot\", \n",
        "                \"fraan\", \"ut\", \"naer\", \"efter\", \"upp\", \"vi\", \n",
        "                \"dem\", \"vara\", \"vad\", \"oever\", \"aen\", \"dig\", \n",
        "                \"kan\", \"sina\", \"haer\", \"ha\", \"mot\", \"alla\", \n",
        "                \"under\", \"naagon\", \"eller\", \"allt\", \"mycket\", \n",
        "                \"sedan\", \"ju\", \"denna\", \"sjaelv\", \"detta\", \n",
        "                \"aat\", \"utan\", \"varit\", \"hur\", \"ingen\", \"mitt\", \n",
        "                \"ni\", \"bli\", \"blev\", \"oss\", \"din\", \"dessa\", \n",
        "                \"naagra\", \"deras\", \"blir\", \"mina\", \"samma\", \n",
        "                \"vilken\", \"er\", \"saadan\", \"vaar\", \"blivit\", \n",
        "                \"dess\", \"inom\", \"mellan\", \"saadant\", \"varfoer\", \n",
        "                \"varje\", \"vilka\", \"ditt\", \"vem\", \"vilket\", \n",
        "                \"sitta\", \"saadana\", \"vart\", \"dina\", \"vars\", \n",
        "                \"vaart\", \"vaara\", \"ert\", \"era\", \"vilka\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "H-HIp3SSa0n0"
      },
      "source": [
        "N√§r vi skapat v√•r lista √§r det dags att skapa en funktion som tar bort dessa fr√•n ett dokument. Denna funktion √§r kodad i cellen nedan. (Igen strunta i lambda f√∂r tillf√§llet.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUriR2ZXa0n0"
      },
      "source": [
        "remove_stopwords = lambda x: ' '.join(y for y in x.split() if y not in my_stop_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rU9ZhSgza0n0"
      },
      "source": [
        "Funktionen ovan tar allts√• bort stoppord fr√•n ett dokument (allts√• en tweet), f√∂r att ta bort stoppord fr√•n hela v√•rt corpus kan funktionen `.apply()`anv√§ndas. \n",
        "\n",
        "**F22.** Skriv den kod som tar bort alla stoppord fr√•n `tweets_low_no_small` och skapar en ny variabel `tweets_low_no_small_stopwords` f√∂r corpuset utan stoppord."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gzm2zfl3a0n0"
      },
      "source": [
        "tweets_low_no_small_stopwords = ...#din kod h√§r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUhucDzga0n0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "7db62649-b2e6-4702-d6b9-de0b6d6f8c27"
      },
      "source": [
        "top_words_low_no_small_stopwords = plot_top_words(tweets_low_no_small_stopwords, 50, 30)\n",
        "top_words_low_no_small_stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a85d85aa98fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtop_words_low_no_small_stopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_top_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_low_no_small_stopwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtop_words_low_no_small_stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plot_top_words' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh4Rjopka0n1"
      },
      "source": [
        "**F23.** Efter att stopporden tagits bort, hur m√•nga g√•nger m√•ste ett ord f√∂rekomma i v√•rt corpus f√∂r att hamna i den nya listan enligt ovan? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "p0ePGiT3a0n1"
      },
      "source": [
        "**F24.** Vad √§r skillnaderna mellan de frekvent f√∂rekommande orden i j√§mf√∂relse med v√•ra tidigare listor? Skriv den kod som j√§mf√∂r dessa tre listor `top_words_lowered`, `top_words_low_no_small` and `top_words_low_no_small_stopwords`, titta p√• de f√∂rsta 20 orden i listorna.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "3SV6__XWa0n1"
      },
      "source": [
        "### Visualisering och rekommendation\n",
        "\n",
        "Dags att visualisera v√•rt resultat och √∂vertyga v√•r klient om att vi hittat de b√§sta debatt√§mnena f√∂r dem! H√§r g√∂r vi det genom att skapa ett word cloud d√§r de mest frekventa orden syns b√§st. \n",
        "\n",
        "Nedanst√•ende kod skapar ett ordmoln f√∂r `top_words_low_no_small_stopwords`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJft-4GNa0n1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "b170c5a9-99dd-4f1c-d0a7-984867397ba6"
      },
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "wordcloud = WordCloud(max_font_size=40)\n",
        "wordcloud.fit_words(top_words_no_small_stopwords.to_dict())\n",
        "plt.figure()\n",
        "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-49174b1c0b9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_font_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mwordcloud\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_words_no_small_stopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwordcloud\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"bilinear\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'top_words_no_small_stopwords' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGXSSDvJa0n1"
      },
      "source": [
        "**F25** √Ñndra i tidigare kod hur m√•nga g√•nger ett ord minst m√•ste finnas f√∂r att det ska inkluderas i ordmolnet. Vad f√∂r√§ndras?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "-cCmk3eMa0n1"
      },
      "source": [
        "**F26** N√§r du tittar p√• ordmolnet, √§r det fler ord som borde vara stoppord? Ange n√•gra stycken och f√∂rklara varf√∂r de b√∂r tas bort."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "DZj0JRKNa0n1"
      },
      "source": [
        "**F27.** Vilket tema rekommenderar ni att publicisten ska ha som debatt√§mne? F√∂rklara svaret. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "lang": "en",
        "id": "jJgzGBhFa0n1"
      },
      "source": [
        "**F28.** Ni har nu arbetat med textdata, hur √§r det annorlunda n√§r det g√§ller pre-processing j√§mf√∂rt med annan typ av data som √§r av mer numerisk eller kategorisk karakt√§r?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjNzexRxa0n1"
      },
      "source": [
        "---\n",
        "*N√§r ni besvarat samtliga fr√•gor och all er kod fungerar i enlighet med instruktioner, gl√∂m d√• inte att l√§mna in en l√§nk till ert repositorie med den f√§rdiga l√∂sningen k√∂rd i era notebooks, senast det datum som √§r angivet. Infoga ocks√• en knapp till Colaboratory om ni anv√§nt er av denna milj√∂*. \n",
        "\n",
        "**Gl√∂m inte heller att versionshantera i GitHub s√• att jag kan f√∂lja ert arbete!** \n",
        "\n",
        "Lycka till!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvs1b76Ma0n1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}